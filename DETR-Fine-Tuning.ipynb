{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\DETR_FineTuning\\DETR-Venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import os\n",
    "\n",
    "from torchvision.datasets import CocoDetection\n",
    "from transformers import DetrImageProcessor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeatbeltCocoDataset(CocoDetection):\n",
    "    \n",
    "    def __init__(self, img_folder, processor):\n",
    "        ann_file = os.path.join(img_folder, \"_annotations.coco.json\")\n",
    "        super(SeatbeltCocoDataset, self).__init__(img_folder, ann_file)\n",
    "        self.processor = processor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # read in PIL image and target in COCO format\n",
    "        # feel free to add data augmentation here before passing them to the next step\n",
    "        img, target = super(SeatbeltCocoDataset, self).__getitem__(idx)\n",
    "        print(target)\n",
    "        \n",
    "        # preprocess image and target (converting target to DETR format, resizing + normalization of both image and target)\n",
    "        image_id = self.ids[idx]\n",
    "        target = {'image_id': image_id, 'annotations': target}\n",
    "        encoding = self.processor(images=img, annotations=target, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze() # remove batch dimension\n",
    "        target = encoding[\"labels\"][0] # remove batch dimension\n",
    "\n",
    "        return pixel_values, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "train_dataset = SeatbeltCocoDataset(img_folder='./data/train', processor=processor)\n",
    "val_dataset = SeatbeltCocoDataset(img_folder='./data//valid', processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 564\n",
      "Number of validation examples: 161\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'image_id': 1, 'category_id': 2, 'bbox': [297, 245, 300, 321], 'area': 96300, 'segmentation': [], 'iscrowd': 0}]\n",
      "(tensor([[[ 2.0777,  2.0263,  2.0948,  ..., -2.0494, -2.1008, -2.0665],\n",
      "         [-0.8164,  1.2728,  2.0948,  ..., -2.0152, -2.0323, -2.1008],\n",
      "         [-0.1999,  1.4098,  2.0948,  ..., -2.0494, -2.0494, -2.1008],\n",
      "         ...,\n",
      "         [-1.9980, -2.0665, -2.1008,  ...,  2.1633,  2.1119,  2.1633],\n",
      "         [-2.1008, -2.1008, -2.1008,  ...,  2.1290,  2.0777,  2.2489],\n",
      "         [-2.0323, -2.0837, -2.1008,  ...,  2.2318,  2.2147,  2.2318]],\n",
      "\n",
      "        [[ 2.1835,  2.1310,  2.2010,  ..., -1.9307, -2.0007, -1.9482],\n",
      "         [-0.7752,  1.3957,  2.2185,  ..., -1.9132, -1.9307, -2.0007],\n",
      "         [-0.1275,  1.5182,  2.2360,  ..., -1.9657, -1.9657, -2.0007],\n",
      "         ...,\n",
      "         [-1.9132, -1.9832, -2.0182,  ...,  2.3410,  2.2885,  2.3410],\n",
      "         [-2.0182, -2.0182, -2.0182,  ...,  2.3060,  2.2535,  2.4286],\n",
      "         [-1.9482, -2.0007, -2.0182,  ...,  2.4111,  2.3936,  2.4111]],\n",
      "\n",
      "        [[ 2.3437,  2.2914,  2.3611,  ..., -1.7347, -1.7870, -1.7696],\n",
      "         [-0.5670,  1.5768,  2.3786,  ..., -1.7173, -1.7347, -1.7870],\n",
      "         [ 0.0605,  1.6988,  2.3960,  ..., -1.7522, -1.7522, -1.8044],\n",
      "         ...,\n",
      "         [-1.6824, -1.7522, -1.7870,  ...,  2.5529,  2.5006,  2.5529],\n",
      "         [-1.7870, -1.7870, -1.7870,  ...,  2.5180,  2.4657,  2.6400],\n",
      "         [-1.7173, -1.7696, -1.7870,  ...,  2.6226,  2.6051,  2.6226]]]), {'size': tensor([800, 800]), 'image_id': tensor([1]), 'class_labels': tensor([2]), 'boxes': tensor([[0.6984, 0.6336, 0.4688, 0.5016]]), 'area': tensor([150468.7500]), 'iscrowd': tensor([0]), 'orig_size': tensor([640, 640])})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values, target = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 800, 800])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'size': tensor([800, 800]), 'image_id': tensor([0]), 'class_labels': tensor([1]), 'boxes': tensor([[0.3109, 0.5367, 0.3750, 0.3734]]), 'area': tensor([89625.]), 'iscrowd': tensor([0]), 'orig_size': tensor([640, 640])}\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "  \n",
    "  pixel_values = [item[0] for item in batch]\n",
    "  encoding = processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "  labels = [item[1] for item in batch]\n",
    "  batch = {}\n",
    "  batch['pixel_values'] = encoding['pixel_values']\n",
    "  batch['pixel_mask'] = encoding['pixel_mask']\n",
    "  batch['labels'] = labels\n",
    "  \n",
    "  return batch\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, collate_fn=collate_fn, batch_size=2)\n",
    "print(len(val_dataloader))\n",
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pixel_values', 'pixel_mask', 'labels'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'size': tensor([800, 800]), 'image_id': tensor([0]), 'class_labels': tensor([1]), 'boxes': tensor([[0.3109, 0.5367, 0.3750, 0.3734]]), 'area': tensor([89625.]), 'iscrowd': tensor([0]), 'orig_size': tensor([640, 640])}\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DETR-Venv",
   "language": "python",
   "name": "detr-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
